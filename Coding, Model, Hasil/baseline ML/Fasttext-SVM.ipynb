{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4pAC6rlpj8h"
   },
   "source": [
    "# Fasttext - BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgebE03Yq0UX"
   },
   "source": [
    "# Install Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3079,
     "status": "ok",
     "timestamp": 1724156410297,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "GxT9cMAnT3yS",
    "outputId": "b2fc7835-b314-4fe9-bf6e-3f72f5e759b9"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24302,
     "status": "ok",
     "timestamp": 1724156434597,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "vfFvbPwXq12X",
    "outputId": "7377272e-9da8-4640-e36a-f0731786f53c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Asiyah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: nlp-id in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (0.1.15.0)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nlp-id) (1.2.2)\n",
      "Requirement already satisfied: nltk==3.8.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nlp-id) (3.8.1)\n",
      "Requirement already satisfied: wget==3.2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nlp-id) (3.2)\n",
      "Requirement already satisfied: pytest==7.3.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nlp-id) (7.3.1)\n",
      "Requirement already satisfied: click in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk==3.8.1->nlp-id) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk==3.8.1->nlp-id) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk==3.8.1->nlp-id) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk==3.8.1->nlp-id) (4.66.5)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from pytest==7.3.1->nlp-id) (2.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from pytest==7.3.1->nlp-id) (24.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from pytest==7.3.1->nlp-id) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from pytest==7.3.1->nlp-id) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from scikit-learn==1.2.2->nlp-id) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from scikit-learn==1.2.2->nlp-id) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from scikit-learn==1.2.2->nlp-id) (3.4.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (4.39.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: torch in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from torch) (2.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from networkx->torch) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.6.1,>=1.5 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from networkx->torch) (1.12.0)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from networkx->torch) (3.8.3)\n",
      "Requirement already satisfied: pandas>=1.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from networkx->torch) (2.2.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from matplotlib>=3.3->networkx->torch) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from pandas>=1.1->networkx->torch) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from pandas>=1.1->networkx->torch) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->networkx->torch) (1.16.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "from nltk.corpus import stopwords\n",
    "!pip install Sastrawi\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "!pip install nlp-id\n",
    "!pip install transformers\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "!pip install torch\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3112,
     "status": "ok",
     "timestamp": 1724156437705,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "6Xr7BkabObA1",
    "outputId": "6d0d066d-fdf4-4656-be70-5346e9157b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk>=3.8->textblob) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from nltk>=3.8->textblob) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\asiyah\\anaconda3\\envs\\asiyah_env\\lib\\site-packages (from click->nltk>=3.8->textblob) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xxdk5_utpnx8"
   },
   "source": [
    "# Init Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3971,
     "status": "ok",
     "timestamp": 1724156441673,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "EIpqk-EJlH5s",
    "outputId": "66a1e8ad-238c-47a1-98be-0a931f1bbe59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Asiyah\\AppData\\Local\\Temp\\ipykernel_13736\\2136667265.py:8: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  dataset = pd.read_excel('E:\\Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/All Dataset\\Prepocessed (3).xlsx', dtype=str, index_col=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id-berita</th>\n",
       "      <th>url</th>\n",
       "      <th>judul</th>\n",
       "      <th>content per paragraf</th>\n",
       "      <th>label-positif</th>\n",
       "      <th>label-persuasif</th>\n",
       "      <th>label-produk</th>\n",
       "      <th>perspektif-tunggal</th>\n",
       "      <th>label-berita</th>\n",
       "      <th>labels</th>\n",
       "      <th>content_lower</th>\n",
       "      <th>content_punct</th>\n",
       "      <th>content_lemma</th>\n",
       "      <th>content_token</th>\n",
       "      <th>content_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>229</td>\n",
       "      <td>https://tekno.sindonews.com/read/807727/776/pe...</td>\n",
       "      <td>Pengertian Absen Online dan Kelebihannya Diban...</td>\n",
       "      <td>Absen Online kini mulai merambah ke berbagai p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>native ads</td>\n",
       "      <td>1</td>\n",
       "      <td>absen online kini mulai merambah ke berbagai p...</td>\n",
       "      <td>absen online kini mulai merambah ke berbagai p...</td>\n",
       "      <td>absen online kini mulai rambah ke bagai usaha ...</td>\n",
       "      <td>['absen', 'online', 'rambah', 'usaha', 'ganti'...</td>\n",
       "      <td>absen online rambah usaha ganti absen manual r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>229</td>\n",
       "      <td>https://tekno.sindonews.com/read/807727/776/pe...</td>\n",
       "      <td>Pengertian Absen Online dan Kelebihannya Diban...</td>\n",
       "      <td>Sebelum mengetahui manfaat absen online bagi p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>native ads</td>\n",
       "      <td>1</td>\n",
       "      <td>sebelum mengetahui manfaat absen online bagi p...</td>\n",
       "      <td>sebelum mengetahui manfaat absen online bagi p...</td>\n",
       "      <td>belum tahu manfaat absen online bagi usaha mar...</td>\n",
       "      <td>['manfaat', 'absen', 'online', 'usaha', 'mari'...</td>\n",
       "      <td>manfaat absen online usaha mari ajar erti lapo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229</td>\n",
       "      <td>https://tekno.sindonews.com/read/807727/776/pe...</td>\n",
       "      <td>Pengertian Absen Online dan Kelebihannya Diban...</td>\n",
       "      <td>Semua data tersebut selanjutnya akan diberikan...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>native ads</td>\n",
       "      <td>1</td>\n",
       "      <td>semua data tersebut selanjutnya akan diberikan...</td>\n",
       "      <td>semua data tersebut selanjutnya akan diberikan...</td>\n",
       "      <td>semua data sebut lanjut akan beri kepada hrd y...</td>\n",
       "      <td>['data', 'hrd', 'tanggung', 'gaji', 'karyawan'...</td>\n",
       "      <td>data hrd tanggung gaji karyawan data hrd rugi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>229</td>\n",
       "      <td>https://tekno.sindonews.com/read/807727/776/pe...</td>\n",
       "      <td>Pengertian Absen Online dan Kelebihannya Diban...</td>\n",
       "      <td>Setiap hari karyawan melakukan absen dengan me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>native ads</td>\n",
       "      <td>1</td>\n",
       "      <td>setiap hari karyawan melakukan absen dengan me...</td>\n",
       "      <td>setiap hari karyawan melakukan absen dengan me...</td>\n",
       "      <td>tiap hari karyawan laku absen dengan tulis jam...</td>\n",
       "      <td>['karyawan', 'laku', 'absen', 'tulis', 'jam', ...</td>\n",
       "      <td>karyawan laku absen tulis jam hadir tanda tang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>229</td>\n",
       "      <td>https://tekno.sindonews.com/read/807727/776/pe...</td>\n",
       "      <td>Pengertian Absen Online dan Kelebihannya Diban...</td>\n",
       "      <td>Sementara, Absen online merupakan sistem absen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>native ads</td>\n",
       "      <td>1</td>\n",
       "      <td>sementara, absen online merupakan sistem absen...</td>\n",
       "      <td>sementara, absen online merupakan sistem absen...</td>\n",
       "      <td>sementara absen online rupa sistem absensi yan...</td>\n",
       "      <td>['absen', 'online', 'rupa', 'sistem', 'absensi...</td>\n",
       "      <td>absen online rupa sistem absensi manfaat jarin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>998</td>\n",
       "      <td>https://cnnindonesia.com/teknologi/20221203102...</td>\n",
       "      <td>Elon Musk Sebut Twitter Tutupi Cerita Kontrove...</td>\n",
       "      <td>Donald Trump yang menjadi lawan Biden sekaligu...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>berita murni</td>\n",
       "      <td>0</td>\n",
       "      <td>donald trump yang menjadi lawan biden sekaligu...</td>\n",
       "      <td>donald trump yang menjadi lawan biden sekalig...</td>\n",
       "      <td>donald trump yang jadi lawan biden sekaligus t...</td>\n",
       "      <td>['donald', 'trump', 'lawan', 'biden', 'tahana'...</td>\n",
       "      <td>donald trump lawan biden tahana coba serang bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>998</td>\n",
       "      <td>https://cnnindonesia.com/teknologi/20221203102...</td>\n",
       "      <td>Elon Musk Sebut Twitter Tutupi Cerita Kontrove...</td>\n",
       "      <td>Dalam utas tersebut, Taibbi mengatakan bahwa a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>berita murni</td>\n",
       "      <td>0</td>\n",
       "      <td>dalam utas tersebut, taibbi mengatakan bahwa a...</td>\n",
       "      <td>dalam utas tersebut, taibbi mengatakan bahwa a...</td>\n",
       "      <td>dalam utas sebut taibbi kata bahwa apa yang ak...</td>\n",
       "      <td>['utas', 'taibbi', 'baca', 'cuplik', 'buah', '...</td>\n",
       "      <td>utas taibbi baca cuplik buah serial dasar ribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>998</td>\n",
       "      <td>https://cnnindonesia.com/teknologi/20221203102...</td>\n",
       "      <td>Elon Musk Sebut Twitter Tutupi Cerita Kontrove...</td>\n",
       "      <td>Namun menurut Taibbi, Twitter pelan-pelan mala...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>berita murni</td>\n",
       "      <td>0</td>\n",
       "      <td>namun menurut taibbi, twitter pelan-pelan mala...</td>\n",
       "      <td>namun menurut taibbi, twitter pelan-pelan mala...</td>\n",
       "      <td>namun turut taibbi twitter pelan malah tambah ...</td>\n",
       "      <td>['taibbi', 'twitter', 'pelan', 'halang', 'hala...</td>\n",
       "      <td>taibbi twitter pelan halang halang alat kontro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>998</td>\n",
       "      <td>https://cnnindonesia.com/teknologi/20221203102...</td>\n",
       "      <td>Elon Musk Sebut Twitter Tutupi Cerita Kontrove...</td>\n",
       "      <td>Taibbi juga menyebut sejumlah partai politik m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>berita murni</td>\n",
       "      <td>0</td>\n",
       "      <td>taibbi juga menyebut sejumlah partai politik m...</td>\n",
       "      <td>taibbi juga menyebut sejumlah partai politik m...</td>\n",
       "      <td>taibbi juga sebut jumlah partai politik milik ...</td>\n",
       "      <td>['taibbi', 'partai', 'politik', 'milik', 'akse...</td>\n",
       "      <td>taibbi partai politik milik akses hadap alat c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>998</td>\n",
       "      <td>https://cnnindonesia.com/teknologi/20221203102...</td>\n",
       "      <td>Elon Musk Sebut Twitter Tutupi Cerita Kontrove...</td>\n",
       "      <td>Mereka bahkan memblok transmisi sendiri via pe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>berita murni</td>\n",
       "      <td>0</td>\n",
       "      <td>mereka bahkan memblok transmisi sendiri via pe...</td>\n",
       "      <td>mereka bahkan memblok transmisi sendiri via pe...</td>\n",
       "      <td>mereka bahkan blok transmisi sendiri via pesan...</td>\n",
       "      <td>['blok', 'transmisi', 'via', 'pesan', 'langsun...</td>\n",
       "      <td>blok transmisi via pesan langsung dm buah alat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id-berita                                                url  \\\n",
       "0          229  https://tekno.sindonews.com/read/807727/776/pe...   \n",
       "1          229  https://tekno.sindonews.com/read/807727/776/pe...   \n",
       "2          229  https://tekno.sindonews.com/read/807727/776/pe...   \n",
       "3          229  https://tekno.sindonews.com/read/807727/776/pe...   \n",
       "4          229  https://tekno.sindonews.com/read/807727/776/pe...   \n",
       "...        ...                                                ...   \n",
       "2497       998  https://cnnindonesia.com/teknologi/20221203102...   \n",
       "2498       998  https://cnnindonesia.com/teknologi/20221203102...   \n",
       "2499       998  https://cnnindonesia.com/teknologi/20221203102...   \n",
       "2500       998  https://cnnindonesia.com/teknologi/20221203102...   \n",
       "2501       998  https://cnnindonesia.com/teknologi/20221203102...   \n",
       "\n",
       "                                                  judul  \\\n",
       "0     Pengertian Absen Online dan Kelebihannya Diban...   \n",
       "1     Pengertian Absen Online dan Kelebihannya Diban...   \n",
       "2     Pengertian Absen Online dan Kelebihannya Diban...   \n",
       "3     Pengertian Absen Online dan Kelebihannya Diban...   \n",
       "4     Pengertian Absen Online dan Kelebihannya Diban...   \n",
       "...                                                 ...   \n",
       "2497  Elon Musk Sebut Twitter Tutupi Cerita Kontrove...   \n",
       "2498  Elon Musk Sebut Twitter Tutupi Cerita Kontrove...   \n",
       "2499  Elon Musk Sebut Twitter Tutupi Cerita Kontrove...   \n",
       "2500  Elon Musk Sebut Twitter Tutupi Cerita Kontrove...   \n",
       "2501  Elon Musk Sebut Twitter Tutupi Cerita Kontrove...   \n",
       "\n",
       "                                   content per paragraf label-positif  \\\n",
       "0     Absen Online kini mulai merambah ke berbagai p...             0   \n",
       "1     Sebelum mengetahui manfaat absen online bagi p...             1   \n",
       "2     Semua data tersebut selanjutnya akan diberikan...             1   \n",
       "3     Setiap hari karyawan melakukan absen dengan me...             1   \n",
       "4     Sementara, Absen online merupakan sistem absen...             1   \n",
       "...                                                 ...           ...   \n",
       "2497  Donald Trump yang menjadi lawan Biden sekaligu...            -1   \n",
       "2498  Dalam utas tersebut, Taibbi mengatakan bahwa a...             0   \n",
       "2499  Namun menurut Taibbi, Twitter pelan-pelan mala...            -1   \n",
       "2500  Taibbi juga menyebut sejumlah partai politik m...            -1   \n",
       "2501  Mereka bahkan memblok transmisi sendiri via pe...            -1   \n",
       "\n",
       "     label-persuasif label-produk perspektif-tunggal  label-berita labels  \\\n",
       "0                  0            1                  1    native ads      1   \n",
       "1                  1            1                  1    native ads      1   \n",
       "2                  0            1                  1    native ads      1   \n",
       "3                  1            0                  1    native ads      1   \n",
       "4                  1            1                  1    native ads      1   \n",
       "...              ...          ...                ...           ...    ...   \n",
       "2497               0            0                  1  berita murni      0   \n",
       "2498               0            0                  1  berita murni      0   \n",
       "2499               0            0                  0  berita murni      0   \n",
       "2500               0            1                  1  berita murni      0   \n",
       "2501               0            0                  1  berita murni      0   \n",
       "\n",
       "                                          content_lower  \\\n",
       "0     absen online kini mulai merambah ke berbagai p...   \n",
       "1     sebelum mengetahui manfaat absen online bagi p...   \n",
       "2     semua data tersebut selanjutnya akan diberikan...   \n",
       "3     setiap hari karyawan melakukan absen dengan me...   \n",
       "4     sementara, absen online merupakan sistem absen...   \n",
       "...                                                 ...   \n",
       "2497  donald trump yang menjadi lawan biden sekaligu...   \n",
       "2498  dalam utas tersebut, taibbi mengatakan bahwa a...   \n",
       "2499  namun menurut taibbi, twitter pelan-pelan mala...   \n",
       "2500  taibbi juga menyebut sejumlah partai politik m...   \n",
       "2501  mereka bahkan memblok transmisi sendiri via pe...   \n",
       "\n",
       "                                          content_punct  \\\n",
       "0     absen online kini mulai merambah ke berbagai p...   \n",
       "1     sebelum mengetahui manfaat absen online bagi p...   \n",
       "2     semua data tersebut selanjutnya akan diberikan...   \n",
       "3     setiap hari karyawan melakukan absen dengan me...   \n",
       "4     sementara, absen online merupakan sistem absen...   \n",
       "...                                                 ...   \n",
       "2497   donald trump yang menjadi lawan biden sekalig...   \n",
       "2498  dalam utas tersebut, taibbi mengatakan bahwa a...   \n",
       "2499  namun menurut taibbi, twitter pelan-pelan mala...   \n",
       "2500  taibbi juga menyebut sejumlah partai politik m...   \n",
       "2501  mereka bahkan memblok transmisi sendiri via pe...   \n",
       "\n",
       "                                          content_lemma  \\\n",
       "0     absen online kini mulai rambah ke bagai usaha ...   \n",
       "1     belum tahu manfaat absen online bagi usaha mar...   \n",
       "2     semua data sebut lanjut akan beri kepada hrd y...   \n",
       "3     tiap hari karyawan laku absen dengan tulis jam...   \n",
       "4     sementara absen online rupa sistem absensi yan...   \n",
       "...                                                 ...   \n",
       "2497  donald trump yang jadi lawan biden sekaligus t...   \n",
       "2498  dalam utas sebut taibbi kata bahwa apa yang ak...   \n",
       "2499  namun turut taibbi twitter pelan malah tambah ...   \n",
       "2500  taibbi juga sebut jumlah partai politik milik ...   \n",
       "2501  mereka bahkan blok transmisi sendiri via pesan...   \n",
       "\n",
       "                                          content_token  \\\n",
       "0     ['absen', 'online', 'rambah', 'usaha', 'ganti'...   \n",
       "1     ['manfaat', 'absen', 'online', 'usaha', 'mari'...   \n",
       "2     ['data', 'hrd', 'tanggung', 'gaji', 'karyawan'...   \n",
       "3     ['karyawan', 'laku', 'absen', 'tulis', 'jam', ...   \n",
       "4     ['absen', 'online', 'rupa', 'sistem', 'absensi...   \n",
       "...                                                 ...   \n",
       "2497  ['donald', 'trump', 'lawan', 'biden', 'tahana'...   \n",
       "2498  ['utas', 'taibbi', 'baca', 'cuplik', 'buah', '...   \n",
       "2499  ['taibbi', 'twitter', 'pelan', 'halang', 'hala...   \n",
       "2500  ['taibbi', 'partai', 'politik', 'milik', 'akse...   \n",
       "2501  ['blok', 'transmisi', 'via', 'pesan', 'langsun...   \n",
       "\n",
       "                                      content_stopwords  \n",
       "0     absen online rambah usaha ganti absen manual r...  \n",
       "1     manfaat absen online usaha mari ajar erti lapo...  \n",
       "2     data hrd tanggung gaji karyawan data hrd rugi ...  \n",
       "3     karyawan laku absen tulis jam hadir tanda tang...  \n",
       "4     absen online rupa sistem absensi manfaat jarin...  \n",
       "...                                                 ...  \n",
       "2497  donald trump lawan biden tahana coba serang bi...  \n",
       "2498  utas taibbi baca cuplik buah serial dasar ribu...  \n",
       "2499  taibbi twitter pelan halang halang alat kontro...  \n",
       "2500  taibbi partai politik milik akses hadap alat c...  \n",
       "2501  blok transmisi via pesan langsung dm buah alat...  \n",
       "\n",
       "[2502 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#r = requests.get('https://docs.google.com/spreadsheet/ccc?key=1i3BBozbnx9HSTkMsfMHChvzYwG_2MiFB06U05gitD8U&output=xlsx')\n",
    "#data = r.content\n",
    "dataset = pd.read_excel('E:\\Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/All Dataset\\Prepocessed (3).xlsx', dtype=str, index_col=None)\n",
    "#dataset = pd.read_excel(data, 'Prepocessed (3)')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1724156441673,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "FElwUGx0pya5",
    "outputId": "852b2c6f-3cca-4df7-9b5e-f37e00671936"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2502"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6vwOZTaaYkN"
   },
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1724156441673,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "0EvAHBHGab4K"
   },
   "outputs": [],
   "source": [
    "# Misalkan menggunakan `content_lemma` sebagai input\n",
    "texts = dataset['content_lemma'].values\n",
    "# Variabel target y adalah kombinasi dari empat label\n",
    "y = dataset['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1724156441673,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "ptzywVV-aez8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#KFold(n_splits=’warn’, shuffle=False, random_state=None)\n",
    "kf = KFold(5, shuffle=True, random_state=0) # Use for KFold classification\n",
    "\n",
    "for train_index, validation_index in kf.split(texts):\n",
    "  #  print(\"TRAIN:\", texts[train_index], \"VALIDATION:\", texts[validation_index])\n",
    "   X_train, X_test = texts[train_index], texts[validation_index]\n",
    "   y_train, y_test = y[train_index], y[validation_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1724156441673,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "QMTjXXl1aumz",
    "outputId": "8a5f25d2-7f97-4c11-bcd6-6676a490e51e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2002,) (2002,)\n",
      "(500,) (500,)\n"
     ]
    }
   ],
   "source": [
    "#Y = dataset['labels']\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1724156441673,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "ZIP0Z0mgqJKS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-zlbsZapcKR"
   },
   "source": [
    "# Word Embedding Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 137550,
     "status": "ok",
     "timestamp": 1724156579220,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "Z0B9f9bypeb5",
    "outputId": "7bde5750-1149-41f2-8951-43325e6a8ef0"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# # Install Gensim\n",
    "# !pip install --upgrade gensim\n",
    "# !pip install fasttext\n",
    "# # Download dan unzip dataset\n",
    "# wrdvec_path = 'cc.id.300.bin.gz'\n",
    "# #if not os.path.exists(wrdvec_path):\n",
    "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.id.300.vec.gz\n",
    "# !gunzip cc.id.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1724156579221,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "RE0ucR_Q7rkw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1724156579221,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "zjUYO4cx74I-",
    "outputId": "3ad211ce-7ec7-4f57-a2d9-606b595404ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10288"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fatures = 100000\n",
    "#Tensorflow Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_fatures,split=' ')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "vocab_size = len(tokenizer.index_word)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1724156579221,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "zgi7DnbGbRYK"
   },
   "outputs": [],
   "source": [
    "# Convert text to sequence of integers\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1724156579221,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "9EkT5-EdbV_t"
   },
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_length = 257  # asumsi maksimal panjang sequence\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1724156579221,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "RcWSHoYwbbcH",
    "outputId": "f5309dd2-3371-4d97-93d6-c4334742e9f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2002, 257)\n",
      "(500, 257)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1724156579811,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "vmjnDUEb8R4R"
   },
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "num_tokens = len(tokenizer.index_word)+1\n",
    "\n",
    "def get_weights(embedding_vectors,embedding_dim):\n",
    "    global num_tokens,tokenizer\n",
    "\n",
    "    # assign vectors to words using the pretrained model embedding_vectors\n",
    "    embedding_weights = np.zeros((num_tokens,embedding_dim))\n",
    "\n",
    "    # count how many words are not assigned with the pretrained model.\n",
    "    # By default, vectors associated to words are zero vectors.\n",
    "    misses = 0\n",
    "\n",
    "    # the index in word_index starts with 1\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        vector = embedding_vectors.get(word)\n",
    "        # the word_index is ordered by word frequency\n",
    "        if i>=num_tokens :\n",
    "            break\n",
    "        elif vector is not None:\n",
    "            embedding_weights[i] = vector\n",
    "        else:\n",
    "            if len(word)<20:\n",
    "                word = Word(word)\n",
    "                word = word.spellcheck()[0][0]\n",
    "                vector = embedding_vectors.get(str(word))\n",
    "                if vector is not None:\n",
    "                    embedding_weights[i] = vector\n",
    "                else:\n",
    "                    misses +=1\n",
    "                    #print(word)\n",
    "            else:\n",
    "                misses +=1\n",
    "                #print(word)\n",
    "\n",
    "    print(f\"The number of missed words is {misses}\")\n",
    "\n",
    "    return embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1724156579812,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "yWqhn-KrObA7",
    "outputId": "d7f92152-5a2e-44fb-a4e3-18b7e58467df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = r\"E:/Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/Pretrained embeddings/cc.id.300-002.vec\"\n",
    "print(os.path.exists(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 186411,
     "status": "ok",
     "timestamp": 1724156766220,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "2aTWXEp28VR5"
   },
   "outputs": [],
   "source": [
    "embedding_vectors_fasttext = {}\n",
    "with open(\"E:/Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/Pretrained embeddings/cc.id.300-002.vec\",\"r\", encoding='utf-8') as file:\n",
    "    file.readline()\n",
    "    for line in file:\n",
    "        word , vector = line.split(maxsplit=1)\n",
    "        vector = np.fromstring(vector,\"float32\",sep=\" \")\n",
    "        embedding_vectors_fasttext[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372449,
     "status": "ok",
     "timestamp": 1724157138664,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "NgxkluIi8mg-",
    "outputId": "7581f9a8-8750-4ba1-88c0-40dff84eec58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missed words is 695\n"
     ]
    }
   ],
   "source": [
    "# assign vectors to words using the pretrained model fasttext\n",
    "embedding_matrix = get_weights(embedding_vectors_fasttext, embedding_dim=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AZ2IvuBO14S"
   },
   "source": [
    "## Saved Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1878,
     "status": "ok",
     "timestamp": 1724157140511,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "SOqTbgijOuwW",
    "outputId": "1665160b-be77-4653-eedc-f52f331221c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix saved to E:/Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/Embeddings Model/FT_svm_embedding.npy\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Menyimpan embedding matrix\n",
    "filename_npy = 'E:/Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/Embeddings Model/FT_svm_embedding.npy'\n",
    "# Simpan embedding matrix ke dalam file .npy\n",
    "np.save(filename_npy, embedding_matrix)\n",
    "\n",
    "print(f\"Embedding matrix saved to {filename_npy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxzQ_HaRSzSx"
   },
   "source": [
    "# Split Word Embedding to Training-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1724157140511,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "Fe9KELKiSw9F"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert training and testing data to vectors using the word embeddings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train_ft \u001b[38;5;241m=\u001b[39m get_weights(X_train, embedding_matrix)  \u001b[38;5;66;03m# Replace with your actual conversion function\u001b[39;00m\n\u001b[0;32m      3\u001b[0m X_test_ft \u001b[38;5;241m=\u001b[39m get_weights(X_test, embedding_matrix)\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mget_weights\u001b[1;34m(embedding_vectors, embedding_dim)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m num_tokens,tokenizer\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# assign vectors to words using the pretrained model embedding_vectors\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m embedding_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_tokens,embedding_dim))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# count how many words are not assigned with the pretrained model.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# By default, vectors associated to words are zero vectors.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m misses \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# Convert training and testing data to vectors using the word embeddings\n",
    "X_train_ft = get_weights(X_train, embedding_matrix)  # Replace with your actual conversion function\n",
    "X_test_ft = get_weights(X_test, embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5VJljDxxLNV"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1724157140512,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "ulCMuEgXezSD"
   },
   "outputs": [],
   "source": [
    "# from keras import Model\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "# from tensorflow.keras.layers import Input, Embedding, Conv1D, Bidirectional, LSTM, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D,concatenate,ConvLSTM1D\n",
    "# from tensorflow.keras.layers import MaxPooling1D\n",
    "# from tensorflow.keras.layers import Flatten\n",
    "# from tensorflow.keras.layers import SpatialDropout1D\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1508,
     "status": "ok",
     "timestamp": 1724157142017,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "F_SJ8YOKZKZF",
    "outputId": "867580c7-88e1-46fb-f3bd-342ff21650a6"
   },
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# embed_dim = 300\n",
    "# vocab_size = len(tokenizer.index_word)+1\n",
    "# model = Sequential()\n",
    "# ## embedding layer\n",
    "\n",
    "# model = Sequential([\n",
    "#     # Lapisan embedding yang mengonversi input integer menjadi vektor dense\n",
    "#     Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=257, weights=[embedding_matrix], trainable=False),\n",
    "#     BatchNormalization(),\n",
    "#     Dropout(0.2),  # Tambahkan Dropout\n",
    "#     # Lapisan BiLSTM\n",
    "#     Bidirectional(LSTM(256, return_sequences=True)),\n",
    "#     GlobalMaxPooling1D(),  # Tambahkan GlobalMaxPooling1D\n",
    "#     # Opsional: Tambahkan dropout untuk regularisasi\n",
    "#     Dropout(0.2),\n",
    "#     # Lapisan Dense untuk klasifikasi\n",
    "#     Dense(2, activation='sigmoid')  # '4' sesuai dengan jumlah label target Anda, sesuaikan jika berbeda\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1724157143621,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "2Wg55icrIuDY",
    "outputId": "22807d96-dd8b-473e-b28e-2b31842741d2"
   },
   "outputs": [],
   "source": [
    "# model.build(input_shape=(None, 257))\n",
    "# # Ringkasan model\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131455,
     "status": "ok",
     "timestamp": 1724157275070,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "eX4F5MUa0TXD",
    "outputId": "6d3580fb-6236-435a-e4a0-b218aa326461"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',  # Gunakan 'sparse_categorical_crossentropy' jika label adalah integer\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(X_train_pad, y_train, epochs=50, batch_size=128, validation_data=(X_test_pad, y_test))\n",
    "# score = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "# print(\"Accuracy: {:.2f}%\".format(score[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "y_train_dl = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_dl = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(x=(X_train_ft, y_train),\n",
    "        validation_data=(X_test_ft, y_test)\n",
    "       )\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Tu8E2CT9Ni0"
   },
   "source": [
    "## Get Evaluate Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1301,
     "status": "ok",
     "timestamp": 1724157276351,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "HCynlzBh5na5"
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test_pad, verbose=0)\n",
    "classes_x=np.rint(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1724157276352,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "0CYUNjNf5qcm"
   },
   "outputs": [],
   "source": [
    "npa = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1724157276352,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "eo2wc8ia5ueu",
    "outputId": "60f1157e-05f4-43e2-8c60-25b4eae3d8a1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision,recall,fscore,support=score(npa,classes_x,average='macro')\n",
    "print('Precision : ',format(precision))\n",
    "print('Recall    : ',format(recall))\n",
    "print('F-score   : ',format(fscore))\n",
    "print('Accuracy : ',accuracy_score(npa, classes_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1724157276352,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "1K47p9eu0mpF",
    "outputId": "28fa9072-440b-423f-e3a5-5e3febe78922"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(npa, classes_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1724157276352,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "SuImxomRKNgn"
   },
   "outputs": [],
   "source": [
    "npa = np.argmax(npa, axis=-1)\n",
    "classes_x = np.argmax(classes_x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1724157277425,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "L9uBOKYPVA_4",
    "outputId": "a1d3c29a-02c8-4b92-dcd8-4416cb8921fc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "labels = [\"News\", \"Native Ads\"]\n",
    "\n",
    "cm = confusion_matrix(npa, classes_x)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mXepIXRerf7"
   },
   "source": [
    "## roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1724157277425,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "QmvAytw6S-sc",
    "outputId": "b6117574-e9f7-45d5-e01d-c5f7959293c0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "y = np.array(npa)\n",
    "\n",
    "scores = np.array(classes_x)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(npa, classes_x)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    " lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1724157277425,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "lC1SjAu9TgMm"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(npa, classes_x)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1724157277425,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "oXYgRXq0TvXx",
    "outputId": "b19aa8c1-ef04-46d5-c376-e0f3ec4e60aa"
   },
   "outputs": [],
   "source": [
    "auc_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1724157277928,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "lQ8MxCcJTdLj",
    "outputId": "2cd874b4-aaeb-4a6e-cb94-13b364eb75fe"
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF (area = {:.3f})'.format(auc_rf))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1724157277929,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "0BkQtuMJkYfH"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr,tpr):\n",
    "  plt.plot(fpr,tpr)\n",
    "  plt.axis([0,1,0,1])\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1724157277929,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "YkkP0epDkZUJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "fpr , tpr , thresholds = roc_curve ( npa , classes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1724157277929,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "GglChJpdkdTz",
    "outputId": "b122be16-cffe-4add-8b7b-1aea76128b14"
   },
   "outputs": [],
   "source": [
    "plot_roc_curve (fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1724157277929,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "QkSh8Qg1kiGr",
    "outputId": "0ac24dce-1496-40d2-ca43-55180e84254f"
   },
   "outputs": [],
   "source": [
    "roc_auc_score(npa,classes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1724157277929,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "kEyAP6xUk_L6",
    "outputId": "4a9034ef-26af-49d6-86f5-aa25a5bc052d"
   },
   "outputs": [],
   "source": [
    "nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(npa, classes_x)\n",
    "auc_keras = auc(nn_fpr_keras, nn_tpr_keras)\n",
    "print(auc_keras)\n",
    "plt.plot(nn_fpr_keras, nn_tpr_keras, marker='.', label='Neural Network (auc = %0.3f)' % auc_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1724157277930,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "CFnVYJHvqTMd"
   },
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)):\n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1724157277930,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "FIZaT7cUqeLg",
    "outputId": "de9c5709-0d65-40b0-8d3f-f283da47970d"
   },
   "outputs": [],
   "source": [
    "perf_measure(npa,classes_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1724157278571,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "7Dz46n58qjMl",
    "outputId": "76ce7150-f78d-40c0-c800-4e383923108a"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1724157278571,
     "user": {
      "displayName": "The fallen of capitalism",
      "userId": "12075089667414372305"
     },
     "user_tz": -420
    },
    "id": "o9cotOpCObBC"
   },
   "source": [
    "# Menampilkan Data Salah Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP_indices = []\n",
    "    FN_indices = []\n",
    "\n",
    "    for i in range(len(y_hat)):\n",
    "        if y_actual[i] == y_hat[i] == 1:\n",
    "            TP += 1\n",
    "        elif y_hat[i] == 1 and y_actual[i] != y_hat[i]:  # False Positive\n",
    "            FP += 1\n",
    "            FP_indices.append(i)\n",
    "        elif y_actual[i] == y_hat[i] == 0:\n",
    "            TN += 1\n",
    "        elif y_hat[i] == 0 and y_actual[i] != y_hat[i]:  # False Negative\n",
    "            FN += 1\n",
    "            FN_indices.append(i)\n",
    "\n",
    "    return(TP, FP, TN, FN, FP_indices, FN_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_measure(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the performance metrics and retrieve indices for FP and FN\n",
    "TP, FP, TN, FN, FP_indices, FN_indices = perf_measure(y_true, y_pred)\n",
    "\n",
    "# Select the FP and FN data from the dataset\n",
    "FP_data = dataset.iloc[FP_indices][['id-berita', 'url', 'content per paragraf']]\n",
    "FN_data = dataset.iloc[FN_indices][['id-berita', 'url', 'content per paragraf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "print(\"False Positives (FP):\")\n",
    "print(FP_data)\n",
    "print('Jumlah dari FP adalah',len(FP_data), 'paragraf.')\n",
    "\n",
    "print(\"\\nFalse Negatives (FN):\")\n",
    "print(FN_data)\n",
    "print('Jumlah dari FN adalah',len(FN_data), 'paragraf.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Specify the folder path\n",
    "folder_path = 'E:/Asiyah/tesis/Thesis Persuasive Detection at Paragraph-Level/Mine/CNN/salah deteksi/'  # Replace this with your desired folder path\n",
    "\n",
    "# Full paths for saving files\n",
    "fp_file_path = os.path.join(folder_path, 'FP_Data_BERT-CNN-Biner.csv')\n",
    "fn_file_path = os.path.join(folder_path, 'FN_Data_BERT-CNN-Biner.csv')\n",
    "\n",
    "# Save FP_data and FN_data to CSV files within the specified folder\n",
    "FP_data.to_csv(fp_file_path, index=False)\n",
    "FN_data.to_csv(fn_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
